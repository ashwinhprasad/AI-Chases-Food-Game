{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradientDescentGame.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_YKG-ItT9ej"
      },
      "source": [
        "# importing the libraries\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edQvfrz_UBKx"
      },
      "source": [
        "# hero position\n",
        "hero_x = torch.tensor(50.,requires_grad=True)\n",
        "hero_y = torch.tensor(50.,requires_grad=True)\n",
        "\n",
        "# food position\n",
        "food_x = torch.tensor(200)\n",
        "food_y = torch.tensor(500)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-Kw9ue-UnGG",
        "outputId": "8106162b-3cff-46ce-df82-2121479dc13a"
      },
      "source": [
        "# learing rate\n",
        "alpha = 10\n",
        "\n",
        "for i in range(100):\n",
        "    # learning rate deacy\n",
        "    if i == 50:\n",
        "        alpha=2\n",
        "    # calculate loss\n",
        "    loss = torch.sqrt((hero_x - food_x)**2 + (hero_y - food_y)**2)\n",
        "    if i%10 == 0:\n",
        "        print(loss)\n",
        "    # gradient descent\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        hero_x -= alpha*hero_x.grad\n",
        "        hero_y -= alpha*hero_y.grad\n",
        "    # reset gradients\n",
        "    hero_x.grad.zero_()\n",
        "    hero_y.grad.zero_()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(474.3416, grad_fn=<SqrtBackward>)\n",
            "tensor(374.3417, grad_fn=<SqrtBackward>)\n",
            "tensor(274.3417, grad_fn=<SqrtBackward>)\n",
            "tensor(174.3416, grad_fn=<SqrtBackward>)\n",
            "tensor(74.3417, grad_fn=<SqrtBackward>)\n",
            "tensor(5.6583, grad_fn=<SqrtBackward>)\n",
            "tensor(1.6583, grad_fn=<SqrtBackward>)\n",
            "tensor(1.6583, grad_fn=<SqrtBackward>)\n",
            "tensor(1.6583, grad_fn=<SqrtBackward>)\n",
            "tensor(1.6583, grad_fn=<SqrtBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N10KbW77XR1X",
        "outputId": "144b531a-69c7-4f12-cf59-c34eb0f83b7e"
      },
      "source": [
        "print(\"After Gradient Descent: \",(hero_x,hero_y))\n",
        "print(\"Expected Output: \",(food_x,food_y))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Gradient Descent:  (tensor(200.5244, requires_grad=True), tensor(501.5732, requires_grad=True))\n",
            "Expected Output:  (tensor(200), tensor(500))\n"
          ]
        }
      ]
    }
  ]
}